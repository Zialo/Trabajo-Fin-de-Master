{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77905c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec38c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import ignite\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from typing import List, Callable\n",
    "import pickle\n",
    "import tqdm\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import os.path\n",
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "#from google.colab import drive\n",
    "#from google.colab.patches import cv2_imshow\n",
    "import fnmatch\n",
    "from math import sqrt\n",
    "from PIL import Image\n",
    "import joblib\n",
    "from torch_lr_finder import LRFinder\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fe0c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.8.1+cu101\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53df23",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7b1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LR = 1e-4\n",
    "WD = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266faa7f",
   "metadata": {},
   "source": [
    "## Data Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdcce9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hodei.zia/ImitAI Project\n",
      "['2000 pruebas', '2000_Pruebas', 'MuJoCo_Dataset', 'Dataset_Mujoco', 'MuJoCo_100_1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Train_dataset',\n",
       " 'Test_dataset',\n",
       " 'MinMax_scaler.save',\n",
       " 'CP',\n",
       " 'CP2',\n",
       " 'resultados.csv',\n",
       " 'model_pytorch_017_LSTMlmYAc_Reg',\n",
       " 'model_pytorch_01796_LSTMlmYAc_Reg',\n",
       " 'model_pytorch_01021_Basico',\n",
       " 'CP3']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modificamos la carpeta \n",
    "print(os.getcwd())\n",
    "try:\n",
    "    print(os.listdir(\"Pruebas ImitAI\"))\n",
    "    os.chdir(\"Pruebas ImitAI/Dataset_Mujoco/Dataset_Mujoco\")\n",
    "except:\n",
    "    print(os.listdir(\"../../Pruebas ImitAI\"))\n",
    "    os.chdir(\"../../Pruebas ImitAI/Dataset_Mujoco/Dataset_Mujoco\")\n",
    "#os.chdir(\"../Prueba\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8226ca77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nres = red_merge(\"Train_dataset/\")\\ncv2_imshow(res)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def red_merge(carpeta_imagenes):\n",
    "    \n",
    "    length = len(fnmatch.filter(os.listdir(carpeta_imagenes + \"Top/\"), '*.png'))\n",
    "    path = carpeta_imagenes + \"Top/0.png\"\n",
    "    img = cv2.imread(path,1)\n",
    "    aux = np.zeros(np.shape(img))\n",
    "    \n",
    "    for idx in range(length):\n",
    "        path = carpeta_imagenes + \"Top/\" + str(idx) + \".png\"\n",
    "\n",
    "        #blurring and smoothin\n",
    "        img=cv2.imread(path,1)\n",
    "\n",
    "        hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "        lower_red = np.array([0,50,50])\n",
    "        upper_red = np.array([10,255,255])\n",
    "\n",
    "        mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "        res = cv2.bitwise_and(img,img, mask= mask)\n",
    "\n",
    "        aux = aux + res\n",
    "    return aux\n",
    "'''\n",
    "res = red_merge(\"Train_dataset/\")\n",
    "cv2_imshow(res)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b3cde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hodei.zia/ImitAI Project/Pruebas ImitAI/Dataset_Mujoco/Dataset_Mujoco'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe602c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hodei.zia/ImitAI Project/Pruebas ImitAI/Dataset_Mujoco/Dataset_Mujoco\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=128x128 at 0x7F6F1045D090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 81.1 ms, sys: 22.6 ms, total: 104 ms\n",
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(os.getcwd())\n",
    "for i in range(1000):\n",
    "    im = Image.open(\"Test_dataset/Top/\"+str(i)+\".png\")\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "685b892a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hodei.zia/ImitAI Project/Pruebas ImitAI/Dataset_Mujoco/Dataset_Mujoco\n",
      "CPU times: user 874 ms, sys: 57.2 ms, total: 931 ms\n",
      "Wall time: 945 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(os.getcwd())\n",
    "for i in range(1000):\n",
    "    image = cv2.imread(\"Test_dataset/Top/\"+str(i)+\".png\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2dcbde",
   "metadata": {},
   "source": [
    "### Normalizamos las acciones y obtenemos el array de tama√±os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d428d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hodei.zia/ImitAI Project/Pruebas ImitAI/Dataset_Mujoco/Dataset_Mujoco\n",
      "['Train_dataset', 'Test_dataset', 'MinMax_scaler.save', 'CP', 'CP2', 'resultados.csv', 'model_pytorch_017_LSTMlmYAc_Reg', 'model_pytorch_01796_LSTMlmYAc_Reg', 'model_pytorch_01021_Basico', 'CP3']\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "print(os.listdir())\n",
    "\n",
    "# Velocities\n",
    "with open('Train_dataset/Train_Actions.csv') as f:\n",
    "    lines = (line for line in f if not line.startswith('#'))\n",
    "    x = np.loadtxt(lines, delimiter=',', skiprows=1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "x_transformed = scaler.fit_transform(x)\n",
    "np.savetxt('Train_dataset/Train_Actions_Normalized.csv',x_transformed , delimiter=',', header=\"X1,X2,X3\")\n",
    "\n",
    "with open('Test_dataset/Test_Actions.csv') as f:\n",
    "    lines = (line for line in f if not line.startswith('#'))\n",
    "    x = np.loadtxt(lines, delimiter=',', skiprows=1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "x_transformed = scaler.fit_transform(x)\n",
    "np.savetxt('Test_dataset/Test_Actions_Normalized.csv',x_transformed , delimiter=',', header=\"X1,X2,X3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20efac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_filename = \"MinMax_scaler.save\"\n",
    "scaler_to_save = MinMaxScaler(feature_range=(-1, 1))\n",
    "joblib.dump(scaler_to_save, scaler_filename) \n",
    "scaler_loaded = joblib.load(scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3586df82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nt_list = [\"Train_dataset\", \"Test_dataset\"]\\nty_list = [\"Top\", \"Corner\", \"Corner2\", \"Corner3\", \"Gripper\", \"BehindGripper\"]\\ncount = 0\\nfor t in t_list:\\n    for ty in ty_list:\\n        f = str(t + \"/\" + ty)\\n        print(f)\\n        for file in os.listdir(f):\\n            f_img = f+\"/\"+file\\n            img = Image.open(f_img)\\n            img = img.resize((128,128))\\n            img.save(f_img)\\n            count += 1\\n            if count % 500 == 0:\\n                print(count)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "t_list = [\"Train_dataset\", \"Test_dataset\"]\n",
    "ty_list = [\"Top\", \"Corner\", \"Corner2\", \"Corner3\", \"Gripper\", \"BehindGripper\"]\n",
    "count = 0\n",
    "for t in t_list:\n",
    "    for ty in ty_list:\n",
    "        f = str(t + \"/\" + ty)\n",
    "        print(f)\n",
    "        for file in os.listdir(f):\n",
    "            f_img = f+\"/\"+file\n",
    "            img = Image.open(f_img)\n",
    "            img = img.resize((128,128))\n",
    "            img.save(f_img)\n",
    "            count += 1\n",
    "            if count % 500 == 0:\n",
    "                print(count)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a329fd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 870\n"
     ]
    }
   ],
   "source": [
    "# Clases para mas de una imagen\n",
    "\n",
    "class ObsActionGetter(object):\n",
    "    \"\"\"\n",
    "    Generic class that return the image and the action given an index\n",
    "    \"\"\"\n",
    "    def __init__(self, carpeta_imagenes, archivo_acciones):\n",
    "        # TODO: get a list of all image files\n",
    "        self.archivo_acciones = archivo_acciones\n",
    "        self.carpeta_imagenes = carpeta_imagenes\n",
    "        path, dirs, files = next(os.walk(self.carpeta_imagenes))\n",
    "        self.image_files = list(range(len(files)))\n",
    "        # TODO: get all made actions\n",
    "        self.actions = []\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(fnmatch.filter(os.listdir(self.carpeta_imagenes + \"Top/\"), '*.png'))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        path_1 = self.carpeta_imagenes + \"Top/\" + str(idx) + \".png\"\n",
    "        path_2 = self.carpeta_imagenes + \"Corner/\" + str(idx) + \".png\"\n",
    "        path_3 = self.carpeta_imagenes + \"Corner2/\" + str(idx) + \".png\"\n",
    "        path_4 = self.carpeta_imagenes + \"Corner3/\" + str(idx) + \".png\"\n",
    "        path_5 = self.carpeta_imagenes + \"Gripper/\" + str(idx) + \".png\"\n",
    "        path_6 = self.carpeta_imagenes + \"BehindGripper/\" + str(idx) + \".png\"\n",
    "        \n",
    "        im1 = np.array(Image.open(path_1))\n",
    "        im2 = np.array(Image.open(path_2))\n",
    "        im3 = np.array(Image.open(path_3))\n",
    "        im4 = np.array(Image.open(path_4))\n",
    "        im5 = np.array(Image.open(path_5))\n",
    "        im6 = np.array(Image.open(path_6))\n",
    "        \n",
    "        # TODO: get the action\n",
    "        data = pd.read_csv(self.archivo_acciones, header = None)\n",
    "        action = np.float32(np.array(data.iloc[idx]))\n",
    "        \n",
    "        if (idx % 25 == 0):\n",
    "            \n",
    "            action_prev_1 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            action_prev_2 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            action_prev_3 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            action_prev_4 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            action_prev_5 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            \n",
    "            im_t = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "            im_prev_1 = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "            im_prev_2 = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "            im_prev_3 = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "            im_prev_4 = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "            im_prev_5 = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "            \n",
    "        elif ((idx-1) % 25 == 0):\n",
    "            action_prev_1 = np.float32(np.array(data.iloc[idx-1]))\n",
    "            action_prev_2 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            action_prev_3 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            action_prev_4 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            action_prev_5 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            \n",
    "            im7 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-1) + \".png\"))\n",
    "            im8 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-1) + \".png\"))\n",
    "            im9 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-1) + \".png\"))\n",
    "            im10 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-1) + \".png\"))\n",
    "            im11 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-1) + \".png\"))\n",
    "            im12 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-1) + \".png\"))\n",
    "            \n",
    "            im_t = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "            im_prev_1 = np.concatenate((im7, im8, im9, im10, im11, im12), axis=2)\n",
    "            im_prev_2 = np.concatenate((im7, im8, im9, im10, im11, im12), axis=2)\n",
    "            im_prev_3 = np.concatenate((im7, im8, im9, im10, im11, im12), axis=2)\n",
    "            im_prev_4 = np.concatenate((im7, im8, im9, im10, im11, im12), axis=2)\n",
    "            im_prev_5 = np.concatenate((im7, im8, im9, im10, im11, im12), axis=2)\n",
    "            \n",
    "        elif ((idx-2) % 25 == 0):\n",
    "            action_prev_1 = np.float32(np.array(data.iloc[idx-1]))\n",
    "            action_prev_2 = np.float32(np.array(data.iloc[idx-2]))\n",
    "            action_prev_3 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            action_prev_4 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            action_prev_5 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            \n",
    "            im7 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-1) + \".png\"))\n",
    "            im8 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-1) + \".png\"))\n",
    "            im9 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-1) + \".png\"))\n",
    "            im10 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-1) + \".png\"))\n",
    "            im11 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-1) + \".png\"))\n",
    "            im12 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-1) + \".png\"))\n",
    "            \n",
    "            im13 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-2) + \".png\"))\n",
    "            im14 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-2) + \".png\"))\n",
    "            im15 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-2) + \".png\"))\n",
    "            im16 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-2) + \".png\"))\n",
    "            im17 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-2) + \".png\"))\n",
    "            im18 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-2) + \".png\"))\n",
    "            \n",
    "            im_t = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "            im_prev_1 = np.concatenate((im7, im8, im9, im10, im11, im12), axis=2)\n",
    "            im_prev_2 = np.concatenate((im13, im14, im15, im16, im17, im18), axis=2)\n",
    "            im_prev_3 = np.concatenate((im13, im14, im15, im16, im17, im18), axis=2)\n",
    "            im_prev_4 = np.concatenate((im13, im14, im15, im16, im17, im18), axis=2)\n",
    "            im_prev_5 = np.concatenate((im13, im14, im15, im16, im17, im18), axis=2)\n",
    "            \n",
    "        elif ((idx-3) % 25 == 0):\n",
    "            action_prev_1 = np.float32(np.array(data.iloc[idx-1]))\n",
    "            action_prev_2 = np.float32(np.array(data.iloc[idx-2]))\n",
    "            action_prev_3 = np.float32(np.array(data.iloc[idx-3]))\n",
    "            action_prev_4 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            action_prev_5 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            \n",
    "            im7 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-1) + \".png\"))\n",
    "            im8 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-1) + \".png\"))\n",
    "            im9 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-1) + \".png\"))\n",
    "            im10 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-1) + \".png\"))\n",
    "            im11 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-1) + \".png\"))\n",
    "            im12 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-1) + \".png\"))\n",
    "            \n",
    "            im13 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-2) + \".png\"))\n",
    "            im14 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-2) + \".png\"))\n",
    "            im15 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-2) + \".png\"))\n",
    "            im16 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-2) + \".png\"))\n",
    "            im17 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-2) + \".png\"))\n",
    "            im18 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-2) + \".png\"))\n",
    "            \n",
    "            im19 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-3) + \".png\"))\n",
    "            im20 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-3) + \".png\"))\n",
    "            im21 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-3) + \".png\"))\n",
    "            im22 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-3) + \".png\"))\n",
    "            im23 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-3) + \".png\"))\n",
    "            im24 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-3) + \".png\"))\n",
    "            \n",
    "            im_t = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "            im_prev_1 = np.concatenate((im7, im8, im9, im10, im11, im12), axis=2)\n",
    "            im_prev_2 = np.concatenate((im13, im14, im15, im16, im17, im18), axis=2)\n",
    "            im_prev_3 = np.concatenate((im19, im20, im21, im22, im23, im24), axis=2)\n",
    "            im_prev_4 = np.concatenate((im19, im20, im21, im22, im23, im24), axis=2)\n",
    "            im_prev_5 = np.concatenate((im19, im20, im21, im22, im23, im24), axis=2)\n",
    "            \n",
    "        elif ((idx-4) % 25 == 0):\n",
    "            action_prev_1 = np.float32(np.array(data.iloc[idx-1]))\n",
    "            action_prev_2 = np.float32(np.array(data.iloc[idx-2]))\n",
    "            action_prev_3 = np.float32(np.array(data.iloc[idx-3]))\n",
    "            action_prev_4 = np.float32(np.array(data.iloc[idx-4]))\n",
    "            action_prev_5 = np.array([0,0,0,0], dtype=\"float32\")\n",
    "            \n",
    "            im7 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-1) + \".png\"))\n",
    "            im8 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-1) + \".png\"))\n",
    "            im9 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-1) + \".png\"))\n",
    "            im10 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-1) + \".png\"))\n",
    "            im11 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-1) + \".png\"))\n",
    "            im12 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-1) + \".png\"))\n",
    "            \n",
    "            im13 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-2) + \".png\"))\n",
    "            im14 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-2) + \".png\"))\n",
    "            im15 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-2) + \".png\"))\n",
    "            im16 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-2) + \".png\"))\n",
    "            im17 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-2) + \".png\"))\n",
    "            im18 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-2) + \".png\"))\n",
    "            \n",
    "            im19 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-3) + \".png\"))\n",
    "            im20 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-3) + \".png\"))\n",
    "            im21 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-3) + \".png\"))\n",
    "            im22 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-3) + \".png\"))\n",
    "            im23 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-3) + \".png\"))\n",
    "            im24 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-3) + \".png\"))\n",
    "            \n",
    "            im25 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-4) + \".png\"))\n",
    "            im26 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-4) + \".png\"))\n",
    "            im27 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-4) + \".png\"))\n",
    "            im28 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-4) + \".png\"))\n",
    "            im29 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-4) + \".png\"))\n",
    "            im30 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-4) + \".png\"))\n",
    "            \n",
    "            im_t = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "            im_prev_1 = np.concatenate((im7, im8, im9, im10, im11, im12), axis=2)\n",
    "            im_prev_2 = np.concatenate((im13, im14, im15, im16, im17, im18), axis=2)\n",
    "            im_prev_3 = np.concatenate((im19, im20, im21, im22, im23, im24), axis=2)\n",
    "            im_prev_4 = np.concatenate((im25, im26, im27, im28, im29, im30), axis=2)\n",
    "            im_prev_5 = np.concatenate((im25, im26, im27, im28, im29, im30), axis=2)\n",
    "            \n",
    "        else:\n",
    "            action_prev_1 = np.float32(np.array(data.iloc[idx-1]))\n",
    "            action_prev_2 = np.float32(np.array(data.iloc[idx-2]))\n",
    "            action_prev_3 = np.float32(np.array(data.iloc[idx-3]))\n",
    "            action_prev_4 = np.float32(np.array(data.iloc[idx-4]))\n",
    "            action_prev_5 = np.float32(np.array(data.iloc[idx-5]))\n",
    "            \n",
    "            im7 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-1) + \".png\"))\n",
    "            im8 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-1) + \".png\"))\n",
    "            im9 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-1) + \".png\"))\n",
    "            im10 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-1) + \".png\"))\n",
    "            im11 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-1) + \".png\"))\n",
    "            im12 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-1) + \".png\"))\n",
    "            \n",
    "            im13 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-2) + \".png\"))\n",
    "            im14 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-2) + \".png\"))\n",
    "            im15 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-2) + \".png\"))\n",
    "            im16 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-2) + \".png\"))\n",
    "            im17 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-2) + \".png\"))\n",
    "            im18 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-2) + \".png\"))\n",
    "            \n",
    "            im19 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-3) + \".png\"))\n",
    "            im20 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-3) + \".png\"))\n",
    "            im21 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-3) + \".png\"))\n",
    "            im22 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-3) + \".png\"))\n",
    "            im23 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-3) + \".png\"))\n",
    "            im24 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-3) + \".png\"))\n",
    "            \n",
    "            im25 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-4) + \".png\"))\n",
    "            im26 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-4) + \".png\"))\n",
    "            im27 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-4) + \".png\"))\n",
    "            im28 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-4) + \".png\"))\n",
    "            im29 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-4) + \".png\"))\n",
    "            im30 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-4) + \".png\"))\n",
    "            \n",
    "            im31 = np.array(Image.open(self.carpeta_imagenes + \"Top/\" + str(idx-5) + \".png\"))\n",
    "            im32 = np.array(Image.open(self.carpeta_imagenes + \"Corner/\" + str(idx-5) + \".png\"))\n",
    "            im33 = np.array(Image.open(self.carpeta_imagenes + \"Corner2/\" + str(idx-5) + \".png\"))\n",
    "            im34 = np.array(Image.open(self.carpeta_imagenes + \"Corner3/\" + str(idx-5) + \".png\"))\n",
    "            im35 = np.array(Image.open(self.carpeta_imagenes + \"Gripper/\" + str(idx-5) + \".png\"))\n",
    "            im36 = np.array(Image.open(self.carpeta_imagenes + \"BehindGripper/\" + str(idx-5) + \".png\"))\n",
    "            \n",
    "            im_t = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "            im_prev_1 = np.concatenate((im7, im8, im9, im10, im11, im12), axis=2)\n",
    "            im_prev_2 = np.concatenate((im13, im14, im15, im16, im17, im18), axis=2)\n",
    "            im_prev_3 = np.concatenate((im19, im20, im21, im22, im23, im24), axis=2)\n",
    "            im_prev_4 = np.concatenate((im25, im26, im27, im28, im29, im30), axis=2)\n",
    "            im_prev_5 = np.concatenate((im31, im32, im33, im34, im35, im36), axis=2)\n",
    "            \n",
    "        #im_actual = np.concatenate((im1, im2, im3, im4, im5, im6), axis=2)\n",
    "        #im_previa = np.concatenate((im7, im8, im9, im10, im11, im12), axis=2)\n",
    "        #imagen = np.concatenate((im_t, im_prev_1), axis=2) # Canales = 2, Anchura = 1 -> 1,1,1...1,2\n",
    "        # Return both image and action\n",
    "        return im_t, im_prev_1, im_prev_2, im_prev_3, im_prev_4, im_prev_5, action, action_prev_1, action_prev_2, action_prev_3, action_prev_4, action_prev_5\n",
    "\n",
    "class ObsActionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for getting the data. In this case, from ObsActionGetter object\n",
    "    \"\"\"\n",
    "    def __init__(self, obs_action_getter: ObsActionGetter, transformations: List[Callable]):\n",
    "        super(ObsActionDataset, self).__init__()\n",
    "        self.obs_action_getter = obs_action_getter\n",
    "        self.transformations = transformations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.obs_action_getter)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im_t, im_prev_1, im_prev_2, im_prev_3, im_prev_4, im_prev_5, action, action_prev_1, action_prev_2, action_prev_3, action_prev_4, action_prev_5 = self.obs_action_getter[idx]\n",
    "        for t in self.transformations:\n",
    "            im_t = t(im_t)\n",
    "            im_prev_1 = t(im_prev_1)\n",
    "            im_prev_2 = t(im_prev_2)\n",
    "            im_prev_3 = t(im_prev_3)\n",
    "            im_prev_4 = t(im_prev_4)\n",
    "            im_prev_5 = t(im_prev_5)\n",
    "        # Return both image and action\n",
    "        return (im_t, im_prev_1, im_prev_2, im_prev_3, im_prev_4, im_prev_5, action_prev_1, action_prev_2, action_prev_3, action_prev_4, action_prev_5), action\n",
    "    \n",
    "class MultiImage(nn.Module):\n",
    "    def __init__(self, fe, clf, lstm, num_layers, hidden):\n",
    "        super(MultiImage, self).__init__()\n",
    "        self.fe = fe\n",
    "        self.clf = clf\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lstm = lstm\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden = hidden\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11 = x\n",
    "        \n",
    "        #LSTM\n",
    "        f1 = self.flatten(self.avg_pool(self.fe(x1)))\n",
    "        f2 = self.flatten(self.avg_pool(self.fe(x2)))\n",
    "        f3 = self.flatten(self.avg_pool(self.fe(x3)))\n",
    "        f4 = self.flatten(self.avg_pool(self.fe(x4)))\n",
    "        f5 = self.flatten(self.avg_pool(self.fe(x5)))\n",
    "        f6 = self.flatten(self.avg_pool(self.fe(x6)))\n",
    "        \n",
    "        aux = [torch.cat((f2, x7), 1), torch.cat((f3, x8), 1), torch.cat((f4, x9), 1), torch.cat((f5, x10), 1), torch.cat((f6, x11), 1)]\n",
    "        \n",
    "        inputs = torch.zeros(len(aux), np.shape(aux[0])[0], np.shape(aux[0])[1])\n",
    "        for i in range(np.shape(inputs)[0]):\n",
    "            inputs[i] = aux[i]\n",
    "        if np.shape(aux[0])[0] == 32:\n",
    "            xlstm = self.lstm(inputs.cuda(), self.hidden)[0][-1]\n",
    "        else: \n",
    "            hidden = (torch.randn(self.num_layers, np.shape(aux[0])[0], np.shape(aux[0])[1]).cuda(), torch.randn(self.num_layers, np.shape(aux[0])[0], np.shape(aux[0])[1]).cuda())\n",
    "            xlstm = self.lstm(inputs.cuda(), hidden)[0][-1]\n",
    "        \n",
    "        xlstm = torch.squeeze(xlstm)\n",
    "        f = torch.cat((f1, xlstm), dim=1)\n",
    "        return self.clf(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0abc4508",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500\n",
      "10500\n",
      "10500\n",
      "10500\n",
      "10500\n",
      "10500\n",
      "42000\n",
      "42000\n",
      "42000\n",
      "42000\n",
      "42000\n",
      "42000\n"
     ]
    }
   ],
   "source": [
    "print(len(fnmatch.filter(os.listdir('Test_dataset/Top'), '*.png')))\n",
    "print(len(fnmatch.filter(os.listdir('Test_dataset/Corner'), '*')))\n",
    "print(len(fnmatch.filter(os.listdir('Test_dataset/Corner2'), '*')))\n",
    "print(len(fnmatch.filter(os.listdir('Test_dataset/Corner3'), '*')))\n",
    "print(len(fnmatch.filter(os.listdir('Test_dataset/Gripper'), '*')))\n",
    "print(len(fnmatch.filter(os.listdir('Test_dataset/BehindGripper'), '*')))\n",
    "\n",
    "print(len(fnmatch.filter(os.listdir('Train_dataset/Top'), '*.png')))\n",
    "print(len(fnmatch.filter(os.listdir('Train_dataset/Corner'), '*')))\n",
    "print(len(fnmatch.filter(os.listdir('Train_dataset/Corner2'), '*')))\n",
    "print(len(fnmatch.filter(os.listdir('Train_dataset/Corner3'), '*')))\n",
    "print(len(fnmatch.filter(os.listdir('Train_dataset/Gripper'), '*')))\n",
    "print(len(fnmatch.filter(os.listdir('Train_dataset/BehindGripper'), '*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b677b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para mas de una imagen\n",
    "\n",
    "# Create train Dataset.\n",
    "# The ToTensor transform converts the image to Tensor in [0, 1] range and makes it channel first\n",
    "# The Normalize transform normalizes the tensor using Imagenet stats\n",
    "\n",
    "train_obs_action_getter = ObsActionGetter('Train_dataset/', 'Train_dataset/Train_Actions.csv')\n",
    "train_dataset = ObsActionDataset(train_obs_action_getter, \n",
    "                                [\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.485, 0.456, 0.406, 0.485, 0.456, 0.406, 0.485, 0.456, 0.406, \n",
    "                                                          0.485, 0.456, 0.406, 0.485, 0.456, 0.406, 0.485, 0.456, 0.406),\n",
    "                                                         (0.229, 0.224, 0.225, 0.229, 0.224, 0.225, 0.229, 0.224, 0.225,\n",
    "                                                          0.229, 0.224, 0.225, 0.229, 0.224, 0.225, 0.229, 0.224, 0.225))\n",
    "                                ])\n",
    "\n",
    "# Create test Dataset.\n",
    "# The ToTensor transform converts the image to Tensor in [0, 1] range and makes it channel first\n",
    "# The Normalize transform normalizes the tensor using Imagenet stats\n",
    "\n",
    "test_obs_action_getter = ObsActionGetter('Test_dataset/', 'Test_dataset/Test_Actions.csv')\n",
    "test_dataset = ObsActionDataset(test_obs_action_getter, \n",
    "                                [\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.485, 0.456, 0.406, 0.485, 0.456, 0.406, 0.485, 0.456, 0.406, \n",
    "                                                          0.485, 0.456, 0.406, 0.485, 0.456, 0.406, 0.485, 0.456, 0.406),\n",
    "                                                         (0.229, 0.224, 0.225, 0.229, 0.224, 0.225, 0.229, 0.224, 0.225,\n",
    "                                                          0.229, 0.224, 0.225, 0.229, 0.224, 0.225, 0.229, 0.224, 0.225))\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7af32bd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n",
      "1312\n",
      "10500\n",
      "329\n",
      "CPU times: user 161 ms, sys: 51.5 ms, total: 212 ms\n",
      "Wall time: 210 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create loaders (class that groups examples in batches)\n",
    "# Uriz: train DataLoader should have shuffle to True\n",
    "# Uriz: test DataLoader should have drop_last to False\n",
    "# Uriz: use more workers to improve the training speed (load data in sever CPU threads). Otherwise we have a CPU -> GPU bottleneck\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=16)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(train_loader))\n",
    "print(len(test_dataset))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a4ed374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(30,34):\\n    print(\"\\nAccion Actual:\", train_obs_action_getter[i][1])\\n    print(\"Accion Previa - 1:\", train_obs_action_getter[i][2])\\n    print(\"Accion Previa - 2:\", train_obs_action_getter[i][3])\\n    print(\"Accion Previa - 3:\", train_obs_action_getter[i][4])\\n    print(\"Accion Previa - 4:\", train_obs_action_getter[i][5])\\n    print(\"Accion Previa - 5:\", train_obs_action_getter[i][6])\\n    '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in range(30,34):\n",
    "    print(\"\\nAccion Actual:\", train_obs_action_getter[i][1])\n",
    "    print(\"Accion Previa - 1:\", train_obs_action_getter[i][2])\n",
    "    print(\"Accion Previa - 2:\", train_obs_action_getter[i][3])\n",
    "    print(\"Accion Previa - 3:\", train_obs_action_getter[i][4])\n",
    "    print(\"Accion Previa - 4:\", train_obs_action_getter[i][5])\n",
    "    print(\"Accion Previa - 5:\", train_obs_action_getter[i][6])\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bba12f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f6efc096c90>\n"
     ]
    }
   ],
   "source": [
    "it = iter(test_loader)\n",
    "first = next(it)\n",
    "second = next(it)\n",
    "print(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3716f2",
   "metadata": {},
   "source": [
    "\n",
    "## Model\n",
    "\n",
    "We use a pretrained ResNet18 for now. We have to remove the classifier head because it is traiend for classification with 1000 classes. We add a custom head to make regression of 7 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d898c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To pretrain\n",
    "model = models.resnet18(pretrained=False)\n",
    "\n",
    "# Change the first convolution\n",
    "new_conv = torch.nn.Conv2d(18, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model = list(model.children())[1:]\n",
    "model = [new_conv] + model\n",
    "model = torch.nn.Sequential(*model)\n",
    "\n",
    "# Get only the feature extractor (remove avgpool and fc layers)\n",
    "fe = nn.Sequential(*list(model.children())[:-2])\n",
    "\n",
    "def freeze_all_but_bn(m):\n",
    "    \"\"\"\n",
    "    Function that set a module as no trainable (not required grad) only if it is not a BatchNorm module\n",
    "    Args:\n",
    "        m: PyTorch Module\n",
    "    \"\"\"\n",
    "    if not isinstance(m, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        if hasattr(m, 'weight') and m.weight is not None:\n",
    "            m.weight.requires_grad_(False)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            m.bias.requires_grad_(False)\n",
    "            \n",
    "def unfreeze_all_but_bn(m):\n",
    "    \"\"\"\n",
    "    Function that set a module as no trainable (not required grad) only if it is not a BatchNorm module\n",
    "    Args:\n",
    "        m: PyTorch Module\n",
    "    \"\"\"\n",
    "    if not isinstance(m, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        if hasattr(m, 'weight') and m.weight is not None:\n",
    "            m.weight.requires_grad_(True)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            m.bias.requires_grad_(True)\n",
    "            \n",
    "# Freeze all but BatchNorm layers of feature extractor\n",
    "# Uriz: if we use the \"normal\" ResNet use the pretained version and freeze all but BN\n",
    "#       only set all trainiable when we change the fitst convolution layer to accept images of 6 dimensions\n",
    "#       if the ResNet is pretrained and freezed the training accuracy is maintained (or increased) and the train time is dreceased\n",
    "fe.apply(freeze_all_but_bn) # Solo usar si no se preentrena la red\n",
    "\n",
    "# Create custom head\n",
    "head_clf = nn.Sequential(\n",
    "    nn.BatchNorm1d(512+512+4),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(512+512+4, 512), \n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(512),   \n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(512, 4)\n",
    ")\n",
    "\n",
    "num_layers = 10\n",
    "dropout = 0.2\n",
    "bidirectional = False\n",
    "hidden = (torch.randn(num_layers, BATCH_SIZE, 512+4).cuda(), torch.randn(num_layers, BATCH_SIZE, 512+4).cuda())\n",
    "lstm = lstm = nn.LSTM(np.shape(hidden[0])[2], np.shape(hidden[0])[2], num_layers = num_layers, bidirectional = bidirectional, dropout = dropout)\n",
    "\n",
    "# Rebuild the model\n",
    "model = MultiImage(fe, head_clf, lstm, num_layers, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079655b",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "523eed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainable class with Pytorch Lightinng\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model, loss_function, total_iterations, lr):\n",
    "        \"\"\"\n",
    "        Constructor of the trainable class\n",
    "        Args:\n",
    "            model: PyTorch model\n",
    "            loss_function: The loss function to use\n",
    "            total_iterations: The total number of iterations for training (num_batches * num_epochs). Used for\n",
    "                                LR Schedule\n",
    "            lr: the max_lr to use for the OneCycleLR policy\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Store params\n",
    "        self.model = model\n",
    "        self.loss_function = loss_function\n",
    "        self.total_iterations = total_iterations\n",
    "        self.lr = lr\n",
    "        # For measure the MSE\n",
    "        self.train_mse = torchmetrics.MeanSquaredError()\n",
    "        self.valid_mse = torchmetrics.MeanSquaredError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward method\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_function(prediction, y)\n",
    "        # Get MSE\n",
    "        self.train_mse(prediction, y)\n",
    "        # Log loss and MSE\n",
    "        self.log(\"training_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_mse', self.train_mse, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        # Return Loss for backward\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, outs):\n",
    "        # log epoch metric\n",
    "        self.log('train_acc_epoch', self.train_mse.compute(), logger=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        prediction = self(x)\n",
    "        loss = self.loss_function(prediction, y)\n",
    "        # Get MSE\n",
    "        self.valid_mse(prediction, y)\n",
    "        # Log loss and MSE\n",
    "        self.log('valid_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_mse', self.valid_mse, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_epoch_end(self, outs):\n",
    "        # log epoch metric\n",
    "        self.log('val_acc_epoch', self.valid_mse.compute(), logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Get Adam optimizer\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        # Set OneCycleLR policy\n",
    "        lr_scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=self.lr,\n",
    "                                                             total_steps=self.total_iterations),\n",
    "            'interval': 'step', 'frequency': 1, 'name': 'lr_logger'\n",
    "        }\n",
    "        return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f13c6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallbackClass(Callback):\n",
    "    def __init__(self, what=\"epochs\", verbose=True):\n",
    "        self.what = what\n",
    "        self.verbose = verbose\n",
    "        self.state = {\"epochs\": 0}\n",
    "        \n",
    "    @property\n",
    "    def state_key(self):\n",
    "        # note: we do not include `verbose` here on purpose\n",
    "        return self._generate_state_key(what=self.what)\n",
    "\n",
    "    def on_train_epoch_end(self, *args, **kwargs):\n",
    "        e = 0\n",
    "        if self.what == \"epochs\":\n",
    "            self.state[\"epochs\"] += 1\n",
    "            \n",
    "        if self.state[\"epochs\"] >= 5:\n",
    "            for param in pl_model.parameters():\n",
    "                param.requires_grad = True # Unfreeze\n",
    "        \n",
    "        for name, param in pl_model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                e = e+1\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.state.update(state_dict)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.state.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fca76d",
   "metadata": {},
   "source": [
    "## Bucle to obtain all the info for differents Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5878bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_List = []\n",
    "Model_List = []\n",
    "Prediction_List = []\n",
    "Label_List = []\n",
    "LR_List = []\n",
    "Loss_List = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e07bf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b0bd0a50df4c098fd7c6cbfccf43d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 871\n",
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 2.54E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | MultiImage       | 33.1 M\n",
      "1 | loss_function | MSELoss          | 0     \n",
      "2 | train_mse     | MeanSquaredError | 0     \n",
      "3 | valid_mse     | MeanSquaredError | 0     \n",
      "---------------------------------------------------\n",
      "21.9 M    Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "33.1 M    Total params\n",
      "132.389   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n",
      "EPOCH NUMERO: 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d22b3d875348a6b6ff4bd70ce34f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Epoch_List = [20]\n",
    "num = len(os.listdir(\"../../../tb_logs/my_model\"))\n",
    "for eps in Epoch_List:\n",
    "    \n",
    "    # 1 - Se genera la red\n",
    "    \n",
    "    # To pretrain\n",
    "    model = models.resnet18(pretrained=False)\n",
    "\n",
    "    # Change the first convolution\n",
    "    new_conv = torch.nn.Conv2d(18, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    model = list(model.children())[1:]\n",
    "    model = [new_conv] + model\n",
    "    model = torch.nn.Sequential(*model)\n",
    "\n",
    "    # Get only the feature extractor (remove avgpool and fc layers)\n",
    "    fe = nn.Sequential(*list(model.children())[:-2])\n",
    "\n",
    "    fe.apply(freeze_all_but_bn) # Solo usar si no se preentrena la red\n",
    "\n",
    "    # Create custom head\n",
    "    head_clf = nn.Sequential(\n",
    "        nn.BatchNorm1d(512+512+4),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Linear(512+512+4, 512), \n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(512),   \n",
    "        nn.Dropout(0.25),\n",
    "        nn.Linear(512, 4)\n",
    "    )\n",
    "    \n",
    "    num_layers = 10\n",
    "    dropout = 0.2\n",
    "    bidirectional = False\n",
    "    hidden = (torch.randn(num_layers, BATCH_SIZE, 512+4).cuda(), torch.randn(num_layers, BATCH_SIZE, 512+4).cuda())\n",
    "    lstm = nn.LSTM(np.shape(hidden[0])[2], np.shape(hidden[0])[2], num_layers = num_layers, bidirectional = bidirectional, dropout = dropout)\n",
    "\n",
    "    # Rebuild the model\n",
    "    model = MultiImage(fe, head_clf, lstm, num_layers, hidden)\n",
    "\n",
    "    # 2 - Se busca el mejor Learning Rate a aplicar como maximo posible\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # We catch the optimizer of our lit_model\n",
    "    # optimizer, lr_scheduler = pl_model.configure_optimizers()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    # Learning State Finder\n",
    "    lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "    lr_finder.range_test(train_loader, end_lr=1, num_iter=100, step_mode=\"exp\")\n",
    "\n",
    "    # Create trainer class\n",
    "    try:\n",
    "        BEST_LR = lr_finder.plot()[1]\n",
    "    except:\n",
    "        BEST_LR = 5.0E-03\n",
    "    print(BEST_LR)\n",
    "    \n",
    "    if BEST_LR > 0.09:\n",
    "        BEST_LR = 5.0E-03\n",
    "\n",
    "    # 3 - Se prepara el Trainer y se entrena con el modelo LitModel\n",
    "    \n",
    "    # Number of iterations for LR Schedule\n",
    "    ITERATIONS_PER_EPOCH = len(train_loader)\n",
    "    \n",
    "    logger = TensorBoardLogger(\"/home/hodei.zia/ImitAI Project/tb_logs\", name=\"my_model\")\n",
    "\n",
    "    # Create PytorchLighting model for training\n",
    "    pl_model = LitModel(model, criterion, total_iterations=ITERATIONS_PER_EPOCH * eps, lr=BEST_LR)\n",
    "\n",
    "    NUM_GPUS = 1 if torch.cuda.is_available() else 0\n",
    "        \n",
    "    numCP = len(os.listdir(\"/home/hodei.zia/ImitAI Project/Pruebas ImitAI/Dataset_Mujoco/CP3/\"))\n",
    "    \n",
    "    # Create de ModelCheckpoint\n",
    "    checkpoint_callback  = pl.callbacks.ModelCheckpoint(dirpath='CP3/CP'+str(numCP+1), \n",
    "                                                        save_top_k=-1, \n",
    "                                                        auto_insert_metric_name=True, \n",
    "                                                        every_n_epochs = 1)\n",
    "    \n",
    "    # Create trainer class\n",
    "    trainer = pl.Trainer(auto_lr_find=True, min_epochs=eps, max_epochs=eps,\n",
    "                         log_every_n_steps=1, gpus=NUM_GPUS, callbacks=[CallbackClass(what=\"epochs\"), checkpoint_callback], logger=logger)\n",
    "    #trainer = pl.Trainer(auto_lr_find=True, min_epochs=eps, max_epochs=eps,\n",
    "    #                     log_every_n_steps=1, gpus=NUM_GPUS, callbacks=[checkpoint_callback], logger=logger)\n",
    "\n",
    "    print(\"EPOCH NUMERO: \" + str(eps))\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.fit(pl_model, train_loader, val_dataloaders=test_loader)\n",
    "    \n",
    "    #num = len(os.listdir(\"/home/hodei.zia/ImitAI Project/tb_logs/my_model\"))\n",
    "    erroresTrainEpoch=[]\n",
    "    erroresValEpoch=[]\n",
    "    erroresTrainStep=[]\n",
    "    erroresValStep=[]\n",
    "    \n",
    "    PATH_TB = os.listdir(\"../../../tb_logs/my_model/version_\" + str(num))[1]\n",
    "    PATH = \"/home/hodei.zia/ImitAI Project/tb_logs/my_model/version_\" + str(num) + \"/\"\n",
    "    path_to_events_file = PATH + PATH_TB\n",
    "    num = num + 1\n",
    "    \n",
    "    # Plot de LOSS \n",
    "    for e in tf.compat.v1.train.summary_iterator(path_to_events_file):\n",
    "        for v in e.summary.value:\n",
    "            if v.tag == 'training_loss_epoch':\n",
    "                erroresTrainEpoch.append(v.simple_value)\n",
    "            if v.tag == 'valid_loss_epoch':\n",
    "                erroresValEpoch.append(v.simple_value)\n",
    "\n",
    "            if v.tag == 'training_loss_step':\n",
    "                erroresTrainStep.append(v.simple_value)\n",
    "            #if v.tag == 'valid_loss_step':\n",
    "            #    erroresValStep.append(v.simple_value)\n",
    "\n",
    "    plt.plot(erroresTrainEpoch, label='Train')\n",
    "    plt.plot(erroresValEpoch, label='Validacion')\n",
    "    plt.title(\"Loss de train y validacion por epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylim(0,0.4)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(erroresTrainStep, label='Train')\n",
    "    #plt.plot(erroresValStep, label='Validacion')\n",
    "    plt.title(\"Loss de train por steps\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylim(0,0.4)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4 - Se predice el resultado\n",
    "    \n",
    "    # Put model on eval mode so we change the BatchNorm and Dropout layers behaviour\n",
    "    model = model.eval()\n",
    "    # Set device (\"cuda\" or GPU if cuda is installed, otherwise in \"cpu\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "\n",
    "    # To concatenate predictions and labels\n",
    "    predictions = None\n",
    "    labels = None\n",
    "    # Surround all for not computing gradients\n",
    "    with torch.no_grad():\n",
    "        # Iterate over test dataset\n",
    "        for x, y in tqdm.notebook.tqdm(test_loader):\n",
    "            # Move to device\n",
    "            x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11 = x\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "            x3 = x3.to(device)\n",
    "            x4 = x4.to(device)\n",
    "            x5 = x5.to(device)\n",
    "            x6 = x6.to(device)\n",
    "            x7 = x7.to(device)\n",
    "            x8 = x8.to(device)\n",
    "            x9 = x9.to(device)\n",
    "            x10 = x10.to(device)\n",
    "            x11 = x11.to(device)\n",
    "            \n",
    "            # Predict\n",
    "            o = model((x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11))\n",
    "            # Concatenate\n",
    "            if predictions is None:\n",
    "                predictions = o\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, o), axis=0)\n",
    "\n",
    "            if labels is None:\n",
    "                labels = y\n",
    "            else:\n",
    "                labels = torch.cat((labels, y), axis=0)\n",
    "\n",
    "        # Move predictions to CPU and to numpy\n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "\n",
    "    mse = sklearn.metrics.mean_squared_error(labels, predictions)\n",
    "    rmse = sqrt(mse)\n",
    "    \n",
    "    print(\"El valor del error cudratico medios (MSE) es igual a \" + str(mse))\n",
    "    print(\"El valor RMSE es igual a \" + str(rmse))\n",
    "\n",
    "    # 5 - Se guardan los resultados \n",
    "    \n",
    "    RMSE_List.append(rmse)\n",
    "    Model_List.append(model)\n",
    "    Prediction_List.append(predictions)\n",
    "    Label_List.append(labels)\n",
    "    LR_List.append(BEST_LR)\n",
    "    #Loss_List.append(lr_finder.history['loss'][lr_finder.history['lr'].index(BEST_LR)])\n",
    "    \n",
    "    print(RMSE_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b895e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num = len(os.listdir(\"/home/hodei.zia/ImitAI Project/tb_logs/my_model\"))\n",
    "erroresTrainEpoch=[]\n",
    "erroresValEpoch=[]\n",
    "erroresTrainStep=[]\n",
    "erroresValStep=[]\n",
    "\n",
    "PATH_TB = os.listdir(\"/home/hodei.zia/ImitAI Project/tb_logs/my_model/version_\" + str(num-1))[0]\n",
    "PATH = \"/home/hodei.zia/ImitAI Project/tb_logs/my_model/version_\" + str(num-1) + \"/\"\n",
    "path_to_events_file = PATH + PATH_TB\n",
    "\n",
    "# Plot de LOSS \n",
    "for e in tf.compat.v1.train.summary_iterator(path_to_events_file):\n",
    "    for v in e.summary.value:\n",
    "        if v.tag == 'training_loss_epoch':\n",
    "            erroresTrainEpoch.append(v.simple_value)\n",
    "        if v.tag == 'valid_loss_epoch':\n",
    "            erroresValEpoch.append(v.simple_value)\n",
    "\n",
    "        if v.tag == 'training_loss_step':\n",
    "            erroresTrainStep.append(v.simple_value)\n",
    "        #if v.tag == 'valid_loss_step':\n",
    "        #    erroresValStep.append(v.simple_value)\n",
    "\n",
    "plt.plot(erroresTrainEpoch, label='Train')\n",
    "plt.plot(erroresValEpoch, label='Validacion')\n",
    "plt.title(\"Loss de train y validacion por epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylim(0,0.4)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(erroresTrainStep, label='Train')\n",
    "#plt.plot(erroresValStep, label='Validacion')\n",
    "plt.title(\"Loss de train por steps\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylim(0,0.4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8480d9ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "print(\"BEST RMSE: \" + str(min(RMSE_List)) + \" in Epoch \" + \n",
    "      str(Epoch_List[(RMSE_List.index(min(RMSE_List)))]) + \" with Batch Size = \" + str(BATCH_SIZE) + \" \\nLR = \" + \n",
    "      str(LR_List[(RMSE_List.index(min(RMSE_List)))]))\n",
    "\n",
    "# Plot de RMSE-Epoch\n",
    "plt.plot(Epoch_List, RMSE_List, color='blue', linewidth = 3, marker='o', markerfacecolor='red', markersize=12)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Evolucion del RMSE por Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Plot del LR-Epoch\n",
    "plt.plot(Epoch_List, LR_List, color='blue', linewidth = 3, marker='o', markerfacecolor='red', markersize=12)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('LR')\n",
    "plt.title('Evolucion del LR por Epochs')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70df1e39",
   "metadata": {},
   "source": [
    "## Print the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d96a94a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Num Epochs mejor prueba: \"+str(Epoch_List[RMSE_List.index(min(RMSE_List))]))\n",
    "print(\"RMSE mejor prueba: \"+str(RMSE_List[RMSE_List.index(min(RMSE_List))]))\n",
    "print(\"\")\n",
    "\n",
    "labels = Label_List[(RMSE_List.index(min(RMSE_List)))]\n",
    "predictions = Prediction_List[(RMSE_List.index(min(RMSE_List)))]\n",
    "\n",
    "# Error promedio de cada una de las articulaciones\n",
    "joint_error = np.zeros(3)\n",
    "minimo = np.zeros(3)\n",
    "maximo = np.zeros(3)\n",
    "for i in range(3):\n",
    "    joint_error[i] = sqrt(sklearn.metrics.mean_squared_error(predictions[:, i], labels[:, i]))\n",
    "    minimo[i] = min(labels[:, i])\n",
    "    maximo[i] = max(labels[:, i])\n",
    "    \n",
    "print(\"Error total por articulacion: \"+str(joint_error))\n",
    "\n",
    "ejes = [\"X\", \"Y\", \"Z\"]\n",
    "for i in range(3):\n",
    "    print(\"Eje \" + ejes[i] + \" [\" + str(round(minimo[i], 2)) + \" - \" + str(round(maximo[i], 2)) + \"] \" +\n",
    "          str(round(abs(round(minimo[i], 2) - round(maximo[i], 2)),2))\n",
    "          , str(round(joint_error[i]*100/round(abs(round(minimo[i], 2) - round(maximo[i], 2)),2),2)) + \"%\")\n",
    "    \n",
    "#MSE por demostracion\n",
    "mseDem=[]\n",
    "rmseDem=[]\n",
    "for j in range(len(pd.read_csv(\"Test_dataset/Test_Actions.csv\", index_col=0))//100-1):\n",
    "    mseDem.append(sklearn.metrics.mean_squared_error(labels[j*100:(j+1)*100], predictions[j*100:(j+1)*100]))\n",
    "    rmseDem.append(sqrt(mseDem[j]))\n",
    "    \n",
    "print(\"Los valores RMSE por demostracion son igual a \"+str(rmseDem[0:5]))\n",
    "print(\"El valor medio de RMSE es \"+str(np.mean(rmseDem)))\n",
    "print(\"El valor maximo de RMSE es \"+str(max(rmseDem))+\" y equivale a la prueba \"+str(np.argmax(rmseDem)))\n",
    "print(\"El valor minimo de RMSE es \"+str(min(rmseDem))+\" y equivale a la prueba \"+str(np.argmin(rmseDem)))\n",
    "print(\"\")\n",
    "mRMSE=sorted(rmseDem)[0:5]\n",
    "print(\"Mejores RMSE: \"+str(mRMSE))\n",
    "print(\"Mejores pruebas: \"+str(rmseDem.index(mRMSE[0]))+\", \"+str(rmseDem.index(mRMSE[1]))+\", \"+str(rmseDem.index(mRMSE[2]))+\", \"+str(rmseDem.index(mRMSE[3]))+\", \"+str(rmseDem.index(mRMSE[4])))\n",
    "print(\"Comienzan en la imagen: \"+str(rmseDem.index(mRMSE[0])*100)+\", \"+str(rmseDem.index(mRMSE[1])*100)+\", \"+str(rmseDem.index(mRMSE[2])*100)+\", \"+str(rmseDem.index(mRMSE[3])*100)+\", \"+str(rmseDem.index(mRMSE[4])*100))\n",
    "print(\"\")\n",
    "pRMSE=sorted(rmseDem,reverse=True)[0:5]\n",
    "print(\"Peores RMSE: \"+str(pRMSE))\n",
    "print(\"Peores pruebas: \"+str(rmseDem.index(pRMSE[0]))+\", \"+str(rmseDem.index(pRMSE[1]))+\", \"+str(rmseDem.index(pRMSE[2]))+\", \"+str(rmseDem.index(pRMSE[3]))+\", \"+str(rmseDem.index(pRMSE[4])))\n",
    "print(\"Comienzan en la imagen: \"+str(rmseDem.index(pRMSE[0])*100)+\", \"+str(rmseDem.index(pRMSE[1])*100)+\", \"+str(rmseDem.index(pRMSE[2])*100)+\", \"+str(rmseDem.index(pRMSE[3])*100)+\", \"+str(rmseDem.index(pRMSE[4])*100))\n",
    "print(\"\")\n",
    "\n",
    "#Ploteamos la primera prueba\n",
    "j=1\n",
    "print(\"RMSE:\",sqrt(sklearn.metrics.mean_squared_error(labels[j*100:(j+1)*100], predictions[j*100:(j+1)*100])))\n",
    "for i in range(3):\n",
    "    plt.plot(predictions[j*100:(j+1)*100, i], label='prediction')\n",
    "    plt.plot(labels[j*100:(j+1)*100, i], label='target')\n",
    "    plt.title(\"Observacion: \" + str(j) +\" - Articulacion \" + str(i+1))\n",
    "    plt.ylim(-3,3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#Ploteamos la peor prueba\n",
    "j=np.argmax(rmseDem)\n",
    "print(\"RMSE:\",sqrt(sklearn.metrics.mean_squared_error(labels[j*100:(j+1)*100], predictions[j*100:(j+1)*100])))\n",
    "for i in range(3):\n",
    "    plt.plot(predictions[j*100:(j+1)*100, i], label='prediction')\n",
    "    plt.plot(labels[j*100:(j+1)*100, i], label='target')\n",
    "    plt.title(\"Observacion: \" + str(j) +\" - Articulacion \" + str(i+1))\n",
    "    plt.ylim(-3,3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#Ploteamos la mejor prueba\n",
    "j=np.argmin(rmseDem)\n",
    "print(\"RMSE:\",sqrt(sklearn.metrics.mean_squared_error(labels[j*100:(j+1)*100], predictions[j*100:(j+1)*100])))\n",
    "for i in range(3):\n",
    "    plt.plot(predictions[j*100:(j+1)*100, i], label='prediction')\n",
    "    plt.plot(labels[j*100:(j+1)*100, i], label='target')\n",
    "    plt.title(\"Observacion: \" + str(j) +\" - Articulacion \" + str(i+1))\n",
    "    plt.ylim(-3,3)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc9740",
   "metadata": {},
   "source": [
    "## Histrogramas de RMSE por demostraciones Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee131a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rmseDem,np.shape(rmseDem)[0],label=\"RMSE\")\n",
    "#plt.bar(np.arange(np.shape(rmseDem)[0]),rmseDem,label=\"RMSE\")\n",
    "#plt.plot(np.arange(np.shape(rmseDem)[0]),rmseDem,label=\"RMSE\")\n",
    "plt.xlabel('RMSE')\n",
    "plt.ylabel('Demostracion')\n",
    "plt.title('Histrogrma de rangos de RMSE test')\n",
    "plt.xlim(0,0.4)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.hist(rmseDem,np.shape(rmseDem)[0],label=\"RMSE\")\n",
    "plt.bar(np.arange(np.shape(rmseDem)[0]),rmseDem,label=\"RMSE\")\n",
    "#plt.plot(np.arange(np.shape(rmseDem)[0]),rmseDem,label=\"RMSE\")\n",
    "plt.xlabel('Demostracion')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Histrogrma de RMSE por demostraciones test')\n",
    "plt.ylim(0,0.4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2fd9b1",
   "metadata": {},
   "source": [
    "## Save the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d9b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fecha del dia en el que se guarda el modelo\n",
    "#Nombre del modelo (en formato acordaado en abril)\n",
    "#Imagenes utilizadas\n",
    "#Acciones utilizadas\n",
    "#Batch_size\n",
    "#Numero de epochs\n",
    "#Prediccion del modelo\n",
    "#Explicaciones extras\n",
    "#RMSE\n",
    "#Errores de cada Eje\n",
    "#Accuracy en el simulador\n",
    "nueva_fila = {'Fecha': datetime.today().strftime('%Y-%m-%d'), \n",
    "              'Modelo': \"2-0123456789_32_20_Pant_ImYAcT-5-LSTMImgYAc_P_0.3852\", \n",
    "              'Imagenes': \"Hasta T-5\", \n",
    "              'Acciones': \"T-5\", \n",
    "              'Batch_size': BATCH_SIZE, \n",
    "              'Epochs': Epoch_List[0], \n",
    "              'Prediccion': \"Posicion\",\n",
    "              'Comentario': \"\",\n",
    "              'RMSE':str(round(RMSE_List[RMSE_List.index(min(RMSE_List))], 6)), \n",
    "              'EjeX':str(round(joint_error[0]*100/round(abs(round(minimo[0], 2) - round(maximo[0], 2)),2),2)) + \" %\", \n",
    "              'EjeY':str(round(joint_error[1]*100/round(abs(round(minimo[1], 2) - round(maximo[1], 2)),2),2)) + \" %\", \n",
    "              'EjeZ':str(round(joint_error[2]*100/round(abs(round(minimo[2], 2) - round(maximo[2], 2)),2),2)) + \" %\", \n",
    "              'AccSim':str(round(0/50*100,2)) + \" %\"}\n",
    "\n",
    "print(nueva_fila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69720af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"resultados.csv\", index_col=0)\n",
    "\n",
    "df = df.append(nueva_fila, ignore_index=True)\n",
    " \n",
    "print(df)\n",
    "\n",
    "df.to_csv('resultados.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ee513",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATOS DEL MODELO:\")\n",
    "print(\" - Numero de Epoch: \" + str(Epoch_List[(RMSE_List.index(min(RMSE_List)))]))\n",
    "print(\" - RMSE: \" + str(min(RMSE_List)))\n",
    "torch.save(Model_List[(RMSE_List.index(min(RMSE_List)))], 'model_pytorch_03852')\n",
    "model = torch.load('model_pytorch_03852')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f231fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImitAI",
   "language": "python",
   "name": "imitai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
